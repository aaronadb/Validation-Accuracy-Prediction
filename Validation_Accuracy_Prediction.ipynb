{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeMf_QVo5inJ",
        "outputId": "9f1a73c0-d5f0-4a4e-b128-584f88f320af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPTrZMCi5cch",
        "outputId": "4d29457c-1285-4cff-bcb5-e8c84b5016be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dataset_hyperEarlyStop\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/Dataset_hyperEarlyStop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data"
      ],
      "metadata": {
        "id": "jxITLKBR02e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f=open(\"dataPartition.txt\")\n",
        "train=f.readline()\n",
        "val=f.readline()\n",
        "test=f.readline()\n",
        "train=train[8:-2]\n",
        "val=val[13:-2]\n",
        "test=test[7:-2]\n",
        "train=train.split(sep=', ')\n",
        "for i in range(0,len(train),1):\n",
        "  train[i]=int(train[i])\n",
        "val=val.split(sep=', ')\n",
        "for i in range(0, len(val),1):\n",
        "  val[i]=int(val[i])\n",
        "test=test.split(sep=', ')\n",
        "for i in range(0, len(test),1):\n",
        "  test[i]=int(test[i])"
      ],
      "metadata": {
        "id": "HE-LTsAx595d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_l=pd.read_csv('train_loss.csv',skiprows=1)\n",
        "e_l=pd.read_csv('eval_loss.csv')\n",
        "e_a=pd.read_csv('eval_acc.csv')"
      ],
      "metadata": {
        "id": "HEwYM3Lxwhab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_l_train=t_l[t_l.index.isin(train)].dropna()\n",
        "t_l_val=t_l[t_l.index.isin(val)].dropna()\n",
        "t_l_test=t_l[t_l.index.isin(test)].dropna()\n",
        "e_l_train=e_l[e_l.index.isin(train)].dropna()\n",
        "e_l_val=e_l[e_l.index.isin(val)].dropna()\n",
        "e_l_test=e_l[e_l.index.isin(test)].dropna()\n",
        "e_a_train=e_l[e_a.index.isin(train)].dropna()\n",
        "e_a_val=e_a[e_a.index.isin(val)].dropna()\n",
        "e_a_test=e_a[e_a.index.isin(test)].dropna()"
      ],
      "metadata": {
        "id": "KRT6Lopv1S-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset, window):\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  for i in range(0, len(dataset),1):\n",
        "    for j in range(0, len(dataset[i])-window, 1):\n",
        "      x=dataset[i,j:j+window]\n",
        "      X.append(x)\n",
        "      y=dataset[i,j+1:j+window+1]\n",
        "      Y.append(y)\n",
        "  return torch.tensor(X), torch.tensor(Y)"
      ],
      "metadata": {
        "id": "sFK15XYO86tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, h_s):\n",
        "    super().__init__()\n",
        "    self.lstm=nn.LSTM(input_size=5, hidden_size=h_s, num_layers=1, batch_first=True)\n",
        "    self.linear=nn.Linear(h_s, 1)\n",
        "  def forward(self, x):\n",
        "    x, _=self.lstm(x)\n",
        "    x=self.linear(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "AaBmUGio-Y4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns=list(e_a.columns)\n",
        "columns=columns[4:]\n",
        "t=e_a_train[columns].to_numpy()\n",
        "X_train,Y_train=create_dataset(t,5)\n",
        "v=e_a_val[columns].to_numpy()\n",
        "X_val,Y_val=create_dataset(v,5)\n",
        "test=e_a_test[columns].to_numpy()\n",
        "X_test,Y_test=create_dataset(test,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZiA5UG-xiTj",
        "outputId": "8f8eeb5a-887f-4aec-dec6-e6bc1eacdf35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-03d40300ff42>:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  return torch.tensor(X), torch.tensor(Y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1=Model(10)\n",
        "model2=Model(30)\n",
        "model3=Model(50)\n",
        "model4=Model(70)\n",
        "model5=Model(90)\n",
        "models=[model1, model2, model3, model4, model5]\n",
        "model_rmse=1000000\n",
        "best_model=None\n",
        "for model in models:\n",
        "  optimizer=optim.Adam(model.parameters())\n",
        "  loss_fn=nn.MSELoss()\n",
        "  loader=data.DataLoader(data.TensorDataset(X_train,Y_train), shuffle=True)\n",
        "  n_epochs=20\n",
        "  for epoch in range(0, n_epochs, 1):\n",
        "      model.train()\n",
        "      for X_batch, Y_batch in loader:\n",
        "          Y_pred = model(X_batch.to(torch.float32))\n",
        "          loss = loss_fn(Y_pred, Y_batch.to(torch.float32))\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      # Validation\n",
        "      if epoch % 100 != 0:\n",
        "          continue\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "          Y_pred = model(X_train.to(torch.float32))\n",
        "          train_rmse = np.sqrt(loss_fn(Y_pred, Y_train))\n",
        "          Y_pred = model(X_val.to(torch.float32))\n",
        "          test_rmse = np.sqrt(loss_fn(Y_pred, Y_val))\n",
        "      print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      Y_pred=model(X_val.to(torch.float32))\n",
        "      test_rmse=np.sqrt(loss_fn(Y_pred, Y_val))\n",
        "  if test_rmse<model_rmse:\n",
        "      model_rmse=test_rmse\n",
        "      best_model=model\n",
        "torch.save(best_model,'model.h5')"
      ],
      "metadata": {
        "id": "EDBnN9yZ8Zjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53783af4-a49d-4c7e-cb6d-aa3d648edee7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train RMSE 0.7908, test RMSE 0.5817\n",
            "Epoch 0: train RMSE 0.9072, test RMSE 0.6375\n",
            "Epoch 0: train RMSE 0.8625, test RMSE 0.5906\n",
            "Epoch 0: train RMSE 0.7918, test RMSE 0.5085\n",
            "Epoch 0: train RMSE 0.9027, test RMSE 0.5793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col1=columns[:5]\n",
        "col2=columns[:10]\n",
        "col3=columns[:20]\n",
        "col4=columns[:30]\n",
        "col5=columns[:60]\n",
        "cols=[col1, col2, col3, col4, col5]\n",
        "v=[5,10,20,30,60]\n",
        "Y=torch.tensor(np.array(e_a_test['epoch_150']))\n",
        "error=[]\n",
        "for i in range(0,len(cols),1):\n",
        "  col=cols[i]\n",
        "  with torch.no_grad():\n",
        "    test=torch.tensor(e_a_test.to_numpy())\n",
        "    while(v[i]!=150):\n",
        "      Y_pred=best_model(test[:,v[i]-5:v[i]].to(torch.float32))\n",
        "      v[i]=v[i]+1\n",
        "      if(v[i]==150):\n",
        "        break\n",
        "      test[:,v[i]]=Y_pred[:,0]\n",
        "    rmse=np.sqrt(loss_fn(Y_pred,Y))\n",
        "    error.append(rmse)"
      ],
      "metadata": {
        "id": "rS_k4U2uxldR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a85fd21a-fc67-43c3-b896-b05c3422a485"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([49])) that is different to the input size (torch.Size([49, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQkSzaPnybVm",
        "outputId": "3418f3d5-3ea0-47dd-e3d2-703ed95bbb3c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(3.8710, dtype=torch.float64),\n",
              " tensor(3.8635, dtype=torch.float64),\n",
              " tensor(3.8732, dtype=torch.float64),\n",
              " tensor(3.8756, dtype=torch.float64),\n",
              " tensor(3.8874, dtype=torch.float64)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}